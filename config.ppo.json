
{
    "packages": {
        "my_rl_components": {
            "path": "/path/to/my/rl/components"
        }
    },
    "components": {
        "env": {
            "package": "my_rl_components",
            "type": "GymnasiumEnvWrapper",
            "env_name": "CartPole-v1"
        },
        "actor_critic": {
            "package": "my_rl_components",
            "type": "MLPActorCritic",
            "observation_space": 4,
            "action_space": 2,
            "hidden_dims": [64, 64]
        },
        "ppo_algorithm": {
            "package": "my_rl_components",
            "type": "PPOAlgorithm",
            "actor_critic_component": "actor_critic",
            "clip_epsilon": 0.2,
            "ppo_epochs": 10,
            "entropy_coef": 0.01,
            "value_loss_coef": 0.5
        },
        "experience_buffer": {
            "package": "my_rl_components",
            "type": "ExperienceBuffer",
            "buffer_size": 2048
        },
        "console_logger": {
            "package": "my_rl_components",
            "type": "ConsoleLogger"
        }
    },
    "hooks": {
        "training_start": ["console_logger"],
        "episode_reset": ["env"],
        "environment_step": ["env"],
        "action_selection": ["actor_critic"],
        "transition_received": ["experience_buffer"],
        "learning_update": ["ppo_algorithm"],
        "episode_end": ["console_logger"]
    },
    "training": {
        "max_episodes": 1000,
        "max_steps_per_episode": 500
    }
}
